{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert the Tensorflow model into tensorflow light model\n",
    "After we build the model using TensorFlow, we will soon notice that the file size is too large and not optimized for deployment, especially on mobile or edge devices. This is where TensorFlow Lite (TFLite) comes into play. TFLite will help us convert the model to a more efficient format in .tflite. This will generate a small binary-sized model that is lightweight, low-latency and having a minor impact on accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\cohenniv\\AppData\\Local\\Temp\\tmp0yd9s9n8\\assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "190053256"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# load the best saved model from our last training\n",
    "myModel = load_model('Models/model_4.h5')\n",
    "\n",
    "# create a TFLiteConverter object from a TensorFlow Keras model \n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(myModel)\n",
    "\n",
    "# converts a Keras model based on instance variable\n",
    "myModel_tflite = converter.convert()\n",
    "\n",
    "# Save the model\n",
    "tflite_model_file = Path('clothing_classifier.tflite')\n",
    "tflite_model_file.write_bytes(myModel_tflite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we converted the model into the tflite file format, we can use it using a TFLite interpreter to see how the model will perform in making a prediction before deploying it on a mobile or edge device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "import tensorflow.lite as tflite\n",
    "# in AWS Lambda, we need to use this import below\n",
    "# import tflite_runtime.interpreter as tflite\n",
    "\n",
    "# Create an interpreter interface for any model in TFLite\n",
    "interpreter = tflite.Interpreter(model_path='clothing_classifier.tflite')\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get a list of input details from the model\n",
    "input_details = interpreter.get_input_details()\n",
    "input_index = input_details[0]['index']\n",
    "\n",
    "# Get a list of output details from the model\n",
    "output_details = interpreter.get_output_details()\n",
    "output_index = output_details[0]['index']\n",
    "\n",
    "labels = ['dress','hat','longsleeve','outwear','pants','shirt','shoes','short','skirt','t-shirt']\n",
    "\n",
    "# Obtain the image location\n",
    "img_loc = 'datasets/test/hat/2a12baab-f020-42e3-8e6b-5d82e3ed0b55.jpg'\n",
    "\n",
    "# load the image using load_img module\n",
    "img = load_img(path=img_loc, target_size=(150,150))\n",
    "\n",
    "# Turn the image into a 4D-array\n",
    "X = np.expand_dims(img, axis=0)\n",
    "\n",
    "# Normalize the image\n",
    "X = X/255.0\n",
    "\n",
    "# Turn the image into a Numpy array with float32 data type\n",
    "X = X.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dress': 2.938265e-39,\n",
       " 'hat': 1.0,\n",
       " 'longsleeve': 5.7889116e-28,\n",
       " 'outwear': 6.6241504e-34,\n",
       " 'pants': 2.938265e-39,\n",
       " 'shirt': 7.830514e-32,\n",
       " 'shoes': 1.0016733e-28,\n",
       " 'short': 2.938265e-39,\n",
       " 'skirt': 1.075138e-37,\n",
       " 't-shirt': 2.7841611e-34}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set the value of the input tensor\n",
    "interpreter.set_tensor(input_index, X)\n",
    "interpreter.invoke()\n",
    "\n",
    "# Get the value of the output tensor\n",
    "preds = interpreter.get_tensor(output_index)\n",
    "dict(zip(labels, preds[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "86e6b2add717718f5bf21852a76e7c9d30624633e42f1fcdc3d858e24c77d439"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
